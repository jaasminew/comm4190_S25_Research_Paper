{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dab53e1-7fc1-4af6-a85c-63b31c0c78fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Personalized Product Blurb Matrix Experiment with Metrics...\n",
      "Generating blurbs for product: AetherGuard AI-Driven Smart Security Hub with model: ChatGPT\n",
      "Generating blurbs for product: AetherGuard AI-Driven Smart Security Hub with model: Claude\n",
      "Generating blurbs for product: AetherGuard AI-Driven Smart Security Hub with model: Gemini\n",
      "Generating blurbs for product: FlexMaster Pro Adjustable Dumbbell Set with model: ChatGPT\n",
      "Generating blurbs for product: FlexMaster Pro Adjustable Dumbbell Set with model: Claude\n",
      "Generating blurbs for product: FlexMaster Pro Adjustable Dumbbell Set with model: Gemini\n",
      "Generating blurbs for product: LuxeGlimmer Solar-Powered LED Statement Necklace with model: ChatGPT\n",
      "Generating blurbs for product: LuxeGlimmer Solar-Powered LED Statement Necklace with model: Claude\n",
      "Generating blurbs for product: LuxeGlimmer Solar-Powered LED Statement Necklace with model: Gemini\n",
      "Generating blurbs for product: TruffleTwist Artisan Black Truffle Infused Olive Oil with model: ChatGPT\n",
      "Generating blurbs for product: TruffleTwist Artisan Black Truffle Infused Olive Oil with model: Claude\n",
      "Generating blurbs for product: TruffleTwist Artisan Black Truffle Infused Olive Oil with model: Gemini\n",
      "Generating blurbs for product: EcoGlow Radiant Skin Revitalizing Serum with model: ChatGPT\n",
      "Generating blurbs for product: EcoGlow Radiant Skin Revitalizing Serum with model: Claude\n",
      "Generating blurbs for product: EcoGlow Radiant Skin Revitalizing Serum with model: Gemini\n",
      "Generating blurbs for product: ErgoSmart LuminaDesk LED Desk Organizer with model: ChatGPT\n",
      "Generating blurbs for product: ErgoSmart LuminaDesk LED Desk Organizer with model: Claude\n",
      "Generating blurbs for product: ErgoSmart LuminaDesk LED Desk Organizer with model: Gemini\n",
      "Generating blurbs for product: PurrfectDreams Heated Cat Bed with model: ChatGPT\n",
      "Generating blurbs for product: PurrfectDreams Heated Cat Bed with model: Claude\n",
      "Generating blurbs for product: PurrfectDreams Heated Cat Bed with model: Gemini\n",
      "Generating blurbs for product: SkyQuest UltraLite All-Terrain Hiking Boots with model: ChatGPT\n",
      "Generating blurbs for product: SkyQuest UltraLite All-Terrain Hiking Boots with model: Claude\n",
      "Generating blurbs for product: SkyQuest UltraLite All-Terrain Hiking Boots with model: Gemini\n",
      "Generating blurbs for product: STEMQuest RoboLab Adventure Kit with model: ChatGPT\n",
      "Generating blurbs for product: STEMQuest RoboLab Adventure Kit with model: Claude\n",
      "Generating blurbs for product: STEMQuest RoboLab Adventure Kit with model: Gemini\n",
      "Generating blurbs for product: LumiGlow Enchanted LED Wall Art Frame with model: ChatGPT\n",
      "Generating blurbs for product: LumiGlow Enchanted LED Wall Art Frame with model: Claude\n",
      "Generating blurbs for product: LumiGlow Enchanted LED Wall Art Frame with model: Gemini\n",
      "Generated 30 rows with blurbs for 5 personas.\n",
      "Results saved to persona_experiments/personalized_blurbs_matrix\n",
      "\n",
      "Model Performance Summary:\n",
      "ChatGPT:\n",
      "  Personalization Score: 0.233\n",
      "  Product Relevance Score: 0.203\n",
      "  Combined Score: 0.218\n",
      "  Average Word Count: 71.0\n",
      "Claude:\n",
      "  Personalization Score: 0.147\n",
      "  Product Relevance Score: 0.043\n",
      "  Combined Score: 0.095\n",
      "  Average Word Count: 60.2\n",
      "Gemini:\n",
      "  Personalization Score: 0.193\n",
      "  Product Relevance Score: 0.055\n",
      "  Combined Score: 0.124\n",
      "  Average Word Count: 54.8\n",
      "\n",
      "Experiment complete! Matrix of personalized blurbs with metrics generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients using environment variables\n",
    "openai_client = OpenAI()  # Will automatically use OPENAI_API_KEY env var\n",
    "anthropic_client = anthropic.Anthropic()  # Will automatically use ANTHROPIC_API_KEY env var\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Define the models to compare\n",
    "models = {\n",
    "    \"ChatGPT\": {\n",
    "        \"name\": \"gpt-4o-mini\",\n",
    "        \"provider\": \"openai\"\n",
    "    },\n",
    "    \"Claude\": {\n",
    "        \"name\": \"claude-3-5-sonnet-20241022\",\n",
    "        \"provider\": \"anthropic\"\n",
    "    },\n",
    "    \"Gemini\": {\n",
    "        \"name\": \"gemini-1.5-pro\",\n",
    "        \"provider\": \"google\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "output_dir = Path(\"persona_experiments\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "####################################\n",
    "# Data Loading Functions\n",
    "####################################\n",
    "\n",
    "def load_persona_data(file_path=\"personalization_data.csv\", num_personas=5):\n",
    "    \"\"\"Load user personas from CSV file\"\"\"\n",
    "    try:\n",
    "        data_df = pd.read_csv(file_path)\n",
    "        personas = []\n",
    "        \n",
    "        for idx, row in data_df.iloc[:num_personas].iterrows():\n",
    "            # Parse liked tweets\n",
    "            liked_tweets = []\n",
    "            try:\n",
    "                tweets_str = row.get(\"liked_tweets\", \"\")\n",
    "                # Try to handle the format as a string representation of a list\n",
    "                if isinstance(tweets_str, str):\n",
    "                    # Clean up the string and split by commas\n",
    "                    cleaned = tweets_str.replace(\"['\", \"\").replace(\"']\", \"\").replace('\"', \"\")\n",
    "                    liked_tweets = [t.strip() for t in cleaned.split(\"','\")]\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing liked tweets: {e}\")\n",
    "            \n",
    "            # Create a clean persona object\n",
    "            persona = {\n",
    "                \"user_id\": row.get(\"user_id\", idx + 1),\n",
    "                \"linkedin_headline\": row.get(\"linkedin_headline\", \"\"),\n",
    "                \"liked_tweets\": liked_tweets,\n",
    "                \"events\": [row.get(\"event_1\", \"\"), row.get(\"event_2\", \"\"), row.get(\"event_3\", \"\")],\n",
    "                \"dwell_times\": parse_array_string(row.get(\"dwell_times\", \"\")),\n",
    "                \"sku_views\": parse_array_string(row.get(\"sku_views\", \"\")),\n",
    "                \"categories\": [row.get(\"cat_gt_1\", \"\"), row.get(\"cat_gt_2\", \"\")]\n",
    "            }\n",
    "            personas.append(persona)\n",
    "        \n",
    "        return personas\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found\")\n",
    "        return []\n",
    "\n",
    "def load_product_data(file_path=\"content_data.csv\"):\n",
    "    \"\"\"Load product data from CSV file\"\"\"\n",
    "    try:\n",
    "        data_df = pd.read_csv(file_path)\n",
    "        products = []\n",
    "        \n",
    "        for idx, row in data_df.iterrows():\n",
    "            # Parse spec bullets\n",
    "            spec_bullets = []\n",
    "            if isinstance(row.get(\"spec_bullets\"), str):\n",
    "                spec_bullets = [bullet.strip() for bullet in row.get(\"spec_bullets\").split(\",\")]\n",
    "            \n",
    "            # Parse SEO keywords\n",
    "            seo_keywords = []\n",
    "            if isinstance(row.get(\"seo_keywords\"), str):\n",
    "                seo_keywords = [keyword.strip() for keyword in row.get(\"seo_keywords\").split(\",\")]\n",
    "            \n",
    "            product = {\n",
    "                \"campaign_id\": row.get(\"campaign_id\", idx + 1),\n",
    "                \"product\": row.get(\"product\", \"\"),\n",
    "                \"theme\": row.get(\"theme\", \"\"),\n",
    "                \"value_prop\": row.get(\"value_prop\", \"\"),\n",
    "                \"target_audience\": row.get(\"target_audience\", \"\"),\n",
    "                \"spec_bullets\": spec_bullets,\n",
    "                \"seo_keywords\": seo_keywords\n",
    "            }\n",
    "            products.append(product)\n",
    "        \n",
    "        return products\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found\")\n",
    "        return []\n",
    "\n",
    "def parse_array_string(array_str):\n",
    "    \"\"\"Parse a string representation of an array into a list of values\"\"\"\n",
    "    if not isinstance(array_str, str):\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Clean up the string and convert to list\n",
    "        clean_str = array_str.strip().strip(\"[]\")\n",
    "        if not clean_str:\n",
    "            return []\n",
    "        \n",
    "        # Try to split by comma\n",
    "        values = [val.strip() for val in clean_str.split(\",\")]\n",
    "        \n",
    "        # Try to convert to appropriate types\n",
    "        result = []\n",
    "        for val in values:\n",
    "            try:\n",
    "                # Try as number first\n",
    "                num_val = float(val)\n",
    "                if num_val.is_integer():\n",
    "                    result.append(int(num_val))\n",
    "                else:\n",
    "                    result.append(num_val)\n",
    "            except ValueError:\n",
    "                # Otherwise keep as string\n",
    "                result.append(val)\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing array string: {e}\")\n",
    "        return []\n",
    "\n",
    "####################################\n",
    "# Prompt Generation\n",
    "####################################\n",
    "\n",
    "def create_persona_prompt(persona, product):\n",
    "    \"\"\"Create a prompt for generating a personalized product blurb\"\"\"\n",
    "    \n",
    "    # Extract professional info from LinkedIn headline\n",
    "    job_title = persona[\"linkedin_headline\"].split(\"|\")[0].strip() if \"|\" in persona[\"linkedin_headline\"] else persona[\"linkedin_headline\"]\n",
    "    industry = persona[\"linkedin_headline\"].split(\"|\")[1].strip() if \"|\" in persona[\"linkedin_headline\"] else \"\"\n",
    "    \n",
    "    # Format liked tweets for better context\n",
    "    tweet_examples = \"\\n\".join([f\"- {tweet}\" for tweet in persona[\"liked_tweets\"][:3]])\n",
    "    \n",
    "    # Format product bullets\n",
    "    product_bullets = \"\\n\".join([f\"- {bullet}\" for bullet in product[\"spec_bullets\"][:5]])\n",
    "    \n",
    "    prompt = (\n",
    "        f\"You are a personalization specialist for an e-commerce platform. Write a concise, \"\n",
    "        f\"personalized product blurb (50-75 words) for the following user persona and product.\\n\\n\"\n",
    "        \n",
    "        f\"USER PERSONA:\\n\"\n",
    "        f\"Professional: {job_title}\\n\"\n",
    "        f\"Industry: {industry}\\n\"\n",
    "        f\"Interests based on social media activity:\\n{tweet_examples}\\n\"\n",
    "        f\"Recently viewed categories: {', '.join(persona['categories'])}\\n\\n\"\n",
    "        \n",
    "        f\"PRODUCT INFORMATION:\\n\"\n",
    "        f\"Product Name: {product['product']}\\n\"\n",
    "        f\"Theme: {product['theme']}\\n\"\n",
    "        f\"Value Proposition: {product['value_prop']}\\n\"\n",
    "        f\"Target Audience: {product['target_audience']}\\n\"\n",
    "        f\"Key Features:\\n{product_bullets}\\n\\n\"\n",
    "        \n",
    "        f\"INSTRUCTIONS:\\n\"\n",
    "        f\"1. Create a personalized product blurb that speaks directly to this specific persona\\n\"\n",
    "        f\"2. Use language and framing that will resonate with their professional background and interests\\n\"\n",
    "        f\"3. Highlight aspects of the product that would be most relevant to them\\n\"\n",
    "        f\"4. Keep the tone professional but engaging\\n\"\n",
    "        f\"5. Be concise (50-75 words)\\n\"\n",
    "        f\"6. Return ONLY the blurb text, nothing else\\n\"\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "####################################\n",
    "# API Calls\n",
    "####################################\n",
    "\n",
    "def call_api(prompt, model_info, max_retries=3):\n",
    "    \"\"\"Call the appropriate API based on model provider with retries\"\"\"\n",
    "    provider = model_info[\"provider\"]\n",
    "    model_name = model_info[\"name\"]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if provider == \"openai\":\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "                \n",
    "            elif provider == \"anthropic\":\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=model_name,\n",
    "                    max_tokens=1024,\n",
    "                    temperature=0.7,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                return response.content[0].text\n",
    "                \n",
    "            elif provider == \"google\":\n",
    "                model = genai.GenerativeModel(model_name)\n",
    "                response = model.generate_content(prompt)\n",
    "                return response.text\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported provider: {provider}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling {provider} API (attempt {attempt + 1}/{max_retries}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                # Exponential backoff\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                return \"API Error: Could not generate blurb.\"\n",
    "\n",
    "####################################\n",
    "# Evaluation Metrics\n",
    "####################################\n",
    "\n",
    "def compute_blurb_metrics(blurb, persona, product):\n",
    "    \"\"\"Compute metrics for evaluating the personalized blurb\"\"\"\n",
    "    try:\n",
    "        # Basic metrics\n",
    "        word_count = len(blurb.split())\n",
    "        \n",
    "        # Check for persona-specific terms\n",
    "        persona_elements = 0\n",
    "        \n",
    "        # Check for job title\n",
    "        if \"|\" in persona[\"linkedin_headline\"]:\n",
    "            job_title = persona[\"linkedin_headline\"].split(\"|\")[0].strip().lower()\n",
    "            industry = persona[\"linkedin_headline\"].split(\"|\")[1].strip().lower()\n",
    "            \n",
    "            if job_title in blurb.lower():\n",
    "                persona_elements += 1\n",
    "            \n",
    "            if industry in blurb.lower():\n",
    "                persona_elements += 1\n",
    "        \n",
    "        # Check for interests from tweets\n",
    "        interest_keywords = extract_keywords_from_tweets(persona[\"liked_tweets\"])\n",
    "        interest_matches = sum(1 for keyword in interest_keywords if keyword.lower() in blurb.lower())\n",
    "        \n",
    "        # Check for product-specific terms\n",
    "        product_elements = 0\n",
    "        \n",
    "        # Check for product name\n",
    "        if product[\"product\"].lower() in blurb.lower():\n",
    "            product_elements += 1\n",
    "        \n",
    "        # Check for theme and value prop\n",
    "        if product[\"theme\"].lower() in blurb.lower():\n",
    "            product_elements += 1\n",
    "            \n",
    "        if product[\"value_prop\"].lower() in blurb.lower():\n",
    "            product_elements += 1\n",
    "        \n",
    "        # Check for product features\n",
    "        feature_count = sum(1 for feature in product[\"spec_bullets\"] if feature.lower() in blurb.lower())\n",
    "        \n",
    "        return {\n",
    "            \"word_count\": word_count,\n",
    "            \"persona_elements\": persona_elements,\n",
    "            \"interest_matches\": interest_matches,\n",
    "            \"product_elements\": product_elements,\n",
    "            \"feature_mentions\": feature_count,\n",
    "            \"personalization_score\": (persona_elements + interest_matches) / (2 + len(interest_keywords)) if interest_keywords else persona_elements / 2,\n",
    "            \"product_relevance_score\": (product_elements + feature_count) / (3 + len(product[\"spec_bullets\"])) if product[\"spec_bullets\"] else product_elements / 3\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing blurb metrics: {str(e)}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"word_count\": 0,\n",
    "            \"personalization_score\": 0,\n",
    "            \"product_relevance_score\": 0\n",
    "        }\n",
    "\n",
    "def extract_keywords_from_tweets(tweets):\n",
    "    \"\"\"Extract potential interest keywords from tweets\"\"\"\n",
    "    if not tweets:\n",
    "        return []\n",
    "    \n",
    "    all_text = \" \".join(tweets)\n",
    "    \n",
    "    # Remove common stop words\n",
    "    stop_words = [\"a\", \"an\", \"the\", \"and\", \"in\", \"on\", \"at\", \"of\", \"for\", \"to\", \"is\", \"are\", \"this\", \"that\", \"with\", \"so\", \"just\"]\n",
    "    \n",
    "    # Split into words, remove punctuation, and filter stop words\n",
    "    words = re.findall(r'\\b\\w+\\b', all_text.lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 3]\n",
    "    \n",
    "    # Get frequency\n",
    "    word_freq = {}\n",
    "    for word in filtered_words:\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "    \n",
    "    # Return top keywords by frequency\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, freq in sorted_words[:10]]  # Return top 10 keywords\n",
    "\n",
    "####################################\n",
    "# Main Experiment Functions\n",
    "####################################\n",
    "\n",
    "def run_personalized_blurbs_matrix_with_metrics():\n",
    "    \"\"\"Generate a matrix of personalized blurbs with metrics for all products and personas\"\"\"\n",
    "    # Load data\n",
    "    personas = load_persona_data(num_personas=5)\n",
    "    products = load_product_data()\n",
    "    \n",
    "    if not personas or not products:\n",
    "        print(\"Error: Could not load data files.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize results structure\n",
    "    matrix_results = []\n",
    "    detailed_metrics = []\n",
    "    \n",
    "    # For each product and model, generate blurbs for all 5 personas\n",
    "    for product in products:\n",
    "        for model_name, model_info in models.items():\n",
    "            print(f\"Generating blurbs for product: {product['product']} with model: {model_name}\")\n",
    "            \n",
    "            # Initialize row with product and model info\n",
    "            row = {\n",
    "                \"product\": product[\"product\"],\n",
    "                \"model\": model_name,\n",
    "            }\n",
    "            \n",
    "            # Track metrics for this product-model combination\n",
    "            model_metrics = {\n",
    "                \"product\": product[\"product\"],\n",
    "                \"model\": model_name,\n",
    "                \"avg_personalization_score\": 0,\n",
    "                \"avg_product_relevance_score\": 0,\n",
    "                \"avg_word_count\": 0,\n",
    "                \"total_persona_elements\": 0,\n",
    "                \"total_interest_matches\": 0,\n",
    "                \"total_product_elements\": 0,\n",
    "                \"total_feature_mentions\": 0\n",
    "            }\n",
    "            \n",
    "            persona_metrics = []\n",
    "            \n",
    "            # Generate a blurb for each persona\n",
    "            for i, persona in enumerate(personas):\n",
    "                persona_key = f\"persona_{persona['user_id']}\"\n",
    "                \n",
    "                # Create a personalized prompt\n",
    "                prompt = create_persona_prompt(persona, product)\n",
    "                \n",
    "                # Generate the blurb\n",
    "                blurb = call_api(prompt, model_info)\n",
    "                \n",
    "                # Clean up the blurb\n",
    "                if blurb:\n",
    "                    blurb = blurb.strip().strip('\"').strip(\"'\")\n",
    "                    blurb = re.sub(r'\\n+', ' ', blurb)  # Replace newlines with spaces\n",
    "                else:\n",
    "                    blurb = \"Failed to generate blurb.\"\n",
    "                \n",
    "                # Add to the row\n",
    "                row[persona_key] = blurb\n",
    "                \n",
    "                # Add persona headline as a separate column for reference\n",
    "                row[f\"persona_{persona['user_id']}_headline\"] = persona[\"linkedin_headline\"]\n",
    "                \n",
    "                # Compute metrics for this blurb\n",
    "                metrics = compute_blurb_metrics(blurb, persona, product)\n",
    "                \n",
    "                # Add metrics to the row\n",
    "                row[f\"persona_{persona['user_id']}_personalization_score\"] = metrics[\"personalization_score\"]\n",
    "                row[f\"persona_{persona['user_id']}_product_relevance_score\"] = metrics[\"product_relevance_score\"]\n",
    "                \n",
    "                # Update overall metrics\n",
    "                model_metrics[\"avg_personalization_score\"] += metrics[\"personalization_score\"]\n",
    "                model_metrics[\"avg_product_relevance_score\"] += metrics[\"product_relevance_score\"]\n",
    "                model_metrics[\"avg_word_count\"] += metrics[\"word_count\"]\n",
    "                model_metrics[\"total_persona_elements\"] += metrics[\"persona_elements\"]\n",
    "                model_metrics[\"total_interest_matches\"] += metrics[\"interest_matches\"]\n",
    "                model_metrics[\"total_product_elements\"] += metrics[\"product_elements\"]\n",
    "                model_metrics[\"total_feature_mentions\"] += metrics[\"feature_mentions\"]\n",
    "                \n",
    "                # Store detailed metrics for this persona-product-model combination\n",
    "                persona_metrics.append({\n",
    "                    \"product\": product[\"product\"],\n",
    "                    \"model\": model_name,\n",
    "                    \"persona_id\": persona[\"user_id\"],\n",
    "                    \"linkedin_headline\": persona[\"linkedin_headline\"],\n",
    "                    \"blurb\": blurb,\n",
    "                    \"word_count\": metrics[\"word_count\"],\n",
    "                    \"persona_elements\": metrics[\"persona_elements\"],\n",
    "                    \"interest_matches\": metrics[\"interest_matches\"],\n",
    "                    \"product_elements\": metrics[\"product_elements\"],\n",
    "                    \"feature_mentions\": metrics[\"feature_mentions\"],\n",
    "                    \"personalization_score\": metrics[\"personalization_score\"],\n",
    "                    \"product_relevance_score\": metrics[\"product_relevance_score\"],\n",
    "                    \"combined_score\": (metrics[\"personalization_score\"] + metrics[\"product_relevance_score\"]) / 2\n",
    "                })\n",
    "            \n",
    "            # Compute averages\n",
    "            num_personas = len(personas)\n",
    "            model_metrics[\"avg_personalization_score\"] /= num_personas\n",
    "            model_metrics[\"avg_product_relevance_score\"] /= num_personas\n",
    "            model_metrics[\"avg_word_count\"] /= num_personas\n",
    "            model_metrics[\"combined_score\"] = (model_metrics[\"avg_personalization_score\"] + model_metrics[\"avg_product_relevance_score\"]) / 2\n",
    "            \n",
    "            # Add summary metrics to the row\n",
    "            row[\"avg_personalization_score\"] = model_metrics[\"avg_personalization_score\"]\n",
    "            row[\"avg_product_relevance_score\"] = model_metrics[\"avg_product_relevance_score\"]\n",
    "            row[\"combined_score\"] = model_metrics[\"combined_score\"]\n",
    "            \n",
    "            # Add completed row to results\n",
    "            matrix_results.append(row)\n",
    "            detailed_metrics.extend(persona_metrics)\n",
    "    \n",
    "    # Create output directory\n",
    "    task_dir = output_dir / \"personalized_blurbs_matrix\"\n",
    "    task_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(matrix_results)\n",
    "    detailed_metrics_df = pd.DataFrame(detailed_metrics)\n",
    "    \n",
    "    # Save as CSV\n",
    "    results_df.to_csv(task_dir / \"personalized_blurbs_matrix.csv\", index=False)\n",
    "    detailed_metrics_df.to_csv(task_dir / \"detailed_metrics.csv\", index=False)\n",
    "    \n",
    "    # Compute overall metrics by model\n",
    "    model_summary = []\n",
    "    for model_name in models.keys():\n",
    "        model_results = [r for r in detailed_metrics if r[\"model\"] == model_name]\n",
    "        \n",
    "        if model_results:\n",
    "            avg_personalization = np.mean([r[\"personalization_score\"] for r in model_results])\n",
    "            avg_product_relevance = np.mean([r[\"product_relevance_score\"] for r in model_results])\n",
    "            avg_combined = np.mean([r[\"combined_score\"] for r in model_results])\n",
    "            avg_word_count = np.mean([r[\"word_count\"] for r in model_results])\n",
    "            \n",
    "            model_summary.append({\n",
    "                \"model\": model_name,\n",
    "                \"avg_personalization_score\": float(avg_personalization),\n",
    "                \"avg_product_relevance_score\": float(avg_product_relevance),\n",
    "                \"avg_combined_score\": float(avg_combined),\n",
    "                \"avg_word_count\": float(avg_word_count),\n",
    "                \"sample_count\": len(model_results)\n",
    "            })\n",
    "    \n",
    "    # Save model summary\n",
    "    model_summary_df = pd.DataFrame(model_summary)\n",
    "    model_summary_df.to_csv(task_dir / \"model_summary.csv\", index=False)\n",
    "    \n",
    "    # Also save as JSON for easier import in other systems\n",
    "    with open(task_dir / \"model_summary.json\", \"w\") as f:\n",
    "        json.dump(model_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"Generated {len(matrix_results)} rows with blurbs for {len(personas)} personas.\")\n",
    "    print(f\"Results saved to {task_dir}\")\n",
    "    \n",
    "    # Print model summary\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    for model in model_summary:\n",
    "        print(f\"{model['model']}:\")\n",
    "        print(f\"  Personalization Score: {model['avg_personalization_score']:.3f}\")\n",
    "        print(f\"  Product Relevance Score: {model['avg_product_relevance_score']:.3f}\")\n",
    "        print(f\"  Combined Score: {model['avg_combined_score']:.3f}\")\n",
    "        print(f\"  Average Word Count: {model['avg_word_count']:.1f}\")\n",
    "    \n",
    "    return matrix_results, detailed_metrics, model_summary\n",
    "\n",
    "####################################\n",
    "# Main Function\n",
    "####################################\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the personalized product blurb matrix experiment with metrics\"\"\"\n",
    "    print(\"Starting Personalized Product Blurb Matrix Experiment with Metrics...\")\n",
    "    \n",
    "    # Check if data files exist\n",
    "    persona_file = Path(\"personalization_data.csv\")\n",
    "    product_file = Path(\"content_data.csv\")\n",
    "    \n",
    "    if not persona_file.exists():\n",
    "        print(\"Error: personalization_data.csv not found.\")\n",
    "        return\n",
    "    \n",
    "    if not product_file.exists():\n",
    "        print(\"Error: content_data.csv not found.\")\n",
    "        return\n",
    "    \n",
    "    # Run the experiment\n",
    "    results, detailed_metrics, model_summary = run_personalized_blurbs_matrix_with_metrics()\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\nExperiment complete! Matrix of personalized blurbs with metrics generated successfully.\")\n",
    "    else:\n",
    "        print(\"\\nError: Experiment failed to generate results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50d922-f884-4a6a-9b3d-455f5c7e437b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
